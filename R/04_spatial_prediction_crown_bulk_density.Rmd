---
title: "Modeling Crown Bulk Density via Ridge Regression"
author: "Johannes Heisig"
output: github_document
---

This analysis predicts Crown Bulk Density, a canopy fuel variable relevant to crown fire spread. It is difficult to sample in the field and therefore estimated using measurements of other forest structure variables and allometric equations. Predictor data for this regression analysis comes from airborne LiDAR and Sentinel-1 & -2.

> NOTE:
> Binder is great for reproducing analysis in R. However, it has RAM restrictions, which can be a problem for large remote sensing data stacks. Below we provide switches for this program, which allow you to decide, whether you want to run all analysis steps or skip some of the computationally expensive ones (e.g. extracting raster values). Alternatively, intermediate results are loaded from existing files. You may choose to download this repository and run operations locally instead.

```{r}
skip_training_data_extraction = T
skip_model_prediction = T

suppressPackageStartupMessages({
library(glmnet)
library(caret)
library(CAST)
library(dplyr)
select = dplyr::select
library(tidyr)
library(ggplot2)
library(stars)
library(sf)
library(parallel)
library(doParallel)
library(patchwork)
})
knitr::opts_chunk$set(cache=T, warning = F, message = F)
```

## Prepare training and predictor data

### Read

```{r warning=FALSE}
if (skip_training_data_extraction){
  haard = readRDS("data/cbd_training_data.rds") |> 
    st_sf() |> 
    select(-c(PlotID, FC_CBH, FC_SH, FC_CC))
} else {
  
  predictors_path = "data/predictors_haard_10m.rds"
  if (! file.exists(predictors_path)){
    download.file("https://uni-muenster.sciebo.de/s/XPEk2uBClq2v3ob/download",
                  predictors_path)
  } else print("Predictor data already on disk.")
  
  p = readRDS("data/predictors_haard_10m.rds") 
  dim(p)
  
  haard = st_read("data/haard_field_plot_locations.csv", crs=4326, quiet=T,
                  options=c("X_POSSIBLE_NAMES=lon","Y_POSSIBLE_NAMES=lat")) |>
    select(plot_id, dom_spp)
  
  FC = read.csv("data/haard_cbd_fuelcalc.csv")[-1,] |> 
    select(PlotID, preCBD, preCBH, preSH, preCC) |> 
    mutate(PlotID = sub(x=PlotID, "-Inventory", "") |> as.numeric(),
           across(2:5, as.numeric)) |> 
    rename_with(~sub("pre","FC_",.x)) |> 
    drop_na() |> 
    glimpse()
}

ft = read_stars("results/haard_surface_fuel_map.tif") |> 
  setNames("FuelType")
```

### Extract

```{r warning=FALSE}
if (!skip_training_data_extraction){
  # Create buffer around visited field plots according to survey protocol
  haard = haard[haard$plot_id %in% FC$PlotID,] |> 
    st_transform(st_crs(p)) |> 
    st_buffer(10)
  
  #' Convert raster data to polygon geometries to enable
  #' intersection rather than pixel-based extraction.
  #' Extract area-weighted values from predictors at plot
  #' locations. First intersect buffers with predictors,
  #' then weight each fragment of a field plot by its 
  #' area in relation to plot size (pi*(10m)² = 314 m²)
  
  haard = st_intersection(st_as_sf(p), haard)
  haard = haard |> 
    mutate(across(-c(plot_id, dom_spp, geometry), 
                  ~as.numeric(.x * st_area(haard)/314))) |> 
    group_by(plot_id) |> 
    summarise(across(where(is.numeric), 
                     function(s) round(sum(s),2)), 
              dom_spp = unique(dom_spp))
  
  # join with target variable (CBD) based on field plot ID
  haard = FC |> 
    mutate(plot_id = as.character(PlotID)) |> 
    select(plot_id, FC_CBD) |> 
    inner_join(haard, by = "plot_id") |> 
    select(-plot_id, -dom_spp) |> 
    st_sf()
}

haard = st_drop_geometry(haard)

# CBD field samples
plot(1:nrow(haard), haard$FC_CBD, col="red")
```


### Fill NAs

```{r message=FALSE, warning=FALSE}
any(colSums(is.na(haard)) > 0) # no NAs in training point data

if (!skip_training_data_extraction){
  # how many NAs in which predictor?
  p.nas = colSums(is.na(as.data.frame(split(p))))
  p.nas[p.nas > 0] 
  
  # ==> NAs mainly in Z-related variables --> can be filled with zeros 
  
  # where in space are NAs?
  p.nas.st = st_apply(p, 1:2, function(x) sum(is.na(x)))
  plot(p.nas.st, breaks = "equal", 
       col = rev(terrain.colors(10)),
       main = "\nNumber of\nmissing predictor values per pixel")
  
  # ==> almost exclusively in non-forest areas --> less of a problem
  
  p = p %>% replace(is.na(.), 0)
}
```


### Split into training and test sets

```{r}
set.seed(111)
training = haard |> sample_frac(0.7)
testing = haard |> setdiff(training)

x_train = model.matrix(FC_CBD ~ ., training)[,-1]   # predictors
x_test = model.matrix(FC_CBD ~ ., testing)[,-1]

y_train = training$FC_CBD                           # target
y_test = testing$FC_CBD
```


### Remove zero variance predictors

```{r message=FALSE, warning=FALSE}
(zerovar = which(apply(scale(x_train), 2, FUN = function(x) {all(is.na(x))})))

x_train = x_train[,-zerovar]
x_test = x_test[,-zerovar]
if (!skip_training_data_extraction) p = p[,,,-zerovar] 
```

## Ridge regression with `caret` and `glmnet`

Prepare model training components:

-   A simple 5-fold random CV is used for assessment of model performance

-   Parameter `lambda` needs to be tuned through cross-validation. We use a tune grid with 100 possible values between 100 and 0.1.

-   Alpha (`a`) determines whether the model performs Ridge regression (`a = 0`), a Lasso regression (`a = 1`), or an Elasticnet regression (`0 < a > 1`).

-   Predictor variables (`p`) are translated from a `stars`-object to a matrix for model prediction.

```{r}
tc = trainControl("cv", 5)
grid = 10^seq(2, -1, length = 100)
a = 0
if (!skip_training_data_extraction){
  newx = p |> 
    split(3) |> 
    as.data.frame() |> 
    select(-x,-y) |> 
    as.matrix()
}
```

### Ridge regression log(CBD)

The `caret` modeling framework will be used as a wrapper for `glmnet`.

```{r}
set.seed(111)
glm_ridge = train(
  x_train,
  log(y_train),
  method = "glmnet",
  preProcess = c("center", "scale"),
  tuneGrid = data.frame(lambda=grid, alpha=0), 
  trControl = tc,
  importance = T)

#saveRDS(glm_ridge, "results/models/model_log_cbd_ridge.rds")
```

### Validation log(CBD)

```{r}
best_lambda = glm_ridge$bestTune$lambda
glm_ridge$results[glm_ridge$results$lambda == best_lambda,]

modelpred = glm_ridge |> 
  predict(s = best_lambda) |> 
  exp()
testpred = glm_ridge |> 
  predict(s = best_lambda, newdata = x_test) |> 
  exp() 
print(round(testpred,3))

R2(modelpred, y_train) # R2 (model prediction vs training data)
R2(testpred, y_test) # R2 (prediction vs validation data)

RMSE(modelpred, y_train) # RMSE (model prediction vs training data)
RMSE(testpred, y_test) # RMSE (prediction vs validation data)
RMSE(mean(y_train), y_test) # RMSE (intercept only model)

plot(varImp(glm_ridge), top=20) 
shapiro.test(residuals(glm_ridge))

hist(residuals(glm_ridge))
plot(log(modelpred), log(y_train), 
     xlim=c(-4,-1), ylim=c(-4,-1))
points(log(testpred),log(y_test), col="red")
abline(0,1)

lambda_index = which(glm_ridge$results$lambda == best_lambda)
coef(glm_ridge$finalModel)[,lambda_index] |> 
  sort(decreasing = T)
```

## Prediction log(CBD)

-   Predict and back-transform to normal scale.

-   Set CBD of non-burnable areas to NA.

-   Calculate the Area of Applicability (AOA).

-   Finally, 117 values (0.013 %) ranging between 0.3 and 10^13 remain. They are considered to be unreasonable for CBD and are also set to NA.

```{r}
if(skip_model_prediction){
  (cbd_glm_st = read_stars("results/haard_CBD.tif") |> 
     setNames("CBD"))
} else {
  cbd_glm = predict(glm_ridge, newdata = newx) |> 
    exp() |> 
    setNames("CBD")
  
  cbd_glm_st = ft |> 
    mutate(CBD = cbd_glm,   
           CBD = case_when(FuelType == 4 ~ NaN,   
                           CBD > 0.3 ~ NaN,
                           TRUE ~ CBD)) |> 
    select(CBD)
}

# Distribution of predicted CBD
hist(cbd_glm_st, breaks=100)
```

AOA

```{r}
if(skip_model_prediction){
  (AOA = read_stars("results/AOA_haard_CBD.tif") |> 
     setNames("AOA"))
} else {
  cl <- makeCluster(6)
  registerDoParallel(cl)
  
  AOA = aoa(model=glm_ridge, newdata=p, cl = cl)
  
  stopCluster(cl)
}
```

Plot

```{r, cache=FALSE}
pcbd = ggplot() + 
  geom_stars(data = cbd_glm_st, downsample = 1) +
  coord_fixed() + 
  scale_x_discrete(expand = c(0, 0), name="") +
  scale_y_discrete(expand = c(0, 0), name="") +
  scale_fill_viridis_c(direction = -1) +
  theme(legend.position = "bottom")

AOA = AOA |> mutate(AOA = factor(AOA, levels = c(0,1), 
                                 labels = c("outside", "inside")))
paoa = ggplot() + 
  geom_stars(data = AOA["AOA"], downsample = 2) +
  coord_equal() + 
  scale_x_discrete(expand = c(0, 0), name="") +
  scale_y_discrete(expand = c(0, 0), name="") +
  scale_fill_viridis_d(option = "E")+
  theme(legend.position = "bottom")

pcbd + paoa
```

About `r round(sum(AOA$AOA == 'outside') / length(AOA$AOA),4)*100`\% of cells fall outside the AOA. However, this mainly concerns non-forested areas. 

```{r, cache=FALSE, include=FALSE}
# write_stars(cbd_glm_st, "results/haard_CBD.tif")
# write_stars(AOA, layer = "AOA", "results/AOA_haard_CBD.tif")
```

